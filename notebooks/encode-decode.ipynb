{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import snntorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 5])\n",
      "torch.Size([2, 8, 5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_spikes = torch.tensor([\n",
    "    [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "])\n",
    "\n",
    "\n",
    "output_spikes_batch = torch.tensor([[\n",
    "    [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    ],\n",
    "    [\n",
    "    [1.0, 1.0, 1.0, 0.0, 1.0],\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    [0.0, 1.0, 0.0, 0.0, 1.0],\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "]])\n",
    "\n",
    "print(output_spikes.shape)\n",
    "print(output_spikes_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_count(spikes):\n",
    "    spike_counts = torch.sum(spikes, dim=1)\n",
    "    action = torch.zeros(spikes.size(0))\n",
    "    max_spike_count = torch.max(spike_counts)\n",
    "    candidates = torch.where(spike_counts == max_spike_count)[0]\n",
    "    if len(candidates) > 1:\n",
    "        action[torch.multinomial(candidates.float(), 1)] = 1\n",
    "    else:\n",
    "        action[candidates] = 1\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_time_to_first_spike(spike_trains):\n",
    "    \n",
    "    decoded_values = torch.full((spike_trains.size(0),), spike_trains.shape[0] + 1)\n",
    "    print(decoded_values)\n",
    "\n",
    "    for i, train in enumerate(spike_trains):\n",
    "\n",
    "        first_spike_time = torch.argmax(train) \n",
    "\n",
    "        if train[first_spike_time] == 1:\n",
    "            decoded_values[i] = first_spike_time.float() + 1\n",
    "\n",
    "    return decoded_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_first_spike(spike_trains):\n",
    "    decoded_vector = [spike_trains.size(0)+1] * spike_trains.size(1)\n",
    "    \n",
    "    for neuron_idx in range(spike_trains.size(1)):\n",
    "        first_spike = (spike_trains[:, neuron_idx] == 1).nonzero(as_tuple=True)[0]\n",
    "        if first_spike.nelement() != 0:\n",
    "            decoded_vector[neuron_idx] = first_spike[0].item() + 1\n",
    "    \n",
    "    return torch.FloatTensor(decoded_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_first_spike_batched(spike_trains):\n",
    "    \"\"\"\n",
    "    Decodes the first spike time from spike trains for batched data using 'time to first spike' method.\n",
    "\n",
    "    Parameters:\n",
    "        spike_trains - The batched spike trains with shape (batch_size, num_steps, num_neurons).\n",
    "\n",
    "    Returns:\n",
    "        decoded_vector - The decoded first spike times with shape (batch_size, num_neurons).\n",
    "    \"\"\"\n",
    "    batch_size = spike_trains.size(0)\n",
    "    num_neurons = spike_trains.size(2)\n",
    "    decoded_vectors = []\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        decoded_vector = [spike_trains.size(1)+1] * num_neurons\n",
    "        \n",
    "        for neuron_idx in range(num_neurons):\n",
    "            first_spike = (spike_trains[batch_idx, :, neuron_idx] == 1).nonzero(as_tuple=True)[0]\n",
    "            if first_spike.nelement() != 0:\n",
    "                decoded_vector[neuron_idx] = first_spike[0].item() + 1\n",
    "        \n",
    "        decoded_vectors.append(decoded_vector)\n",
    "\n",
    "    return torch.FloatTensor(decoded_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3., 1., 9., 5.],\n",
      "        [1., 1., 1., 9., 1.]])\n"
     ]
    }
   ],
   "source": [
    "decoded_trains_batch = decode_first_spike_batched(output_spikes_batch)\n",
    "\n",
    "print(decoded_trains_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Decode the output spikes\n",
    "decoded_trains_batch = decode_count(output_spikes)\n",
    "print(decoded_trains_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.4173e-01, 8.8927e-02, 6.5709e-01, 2.2043e-04, 1.2035e-02])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "p_actions = torch.nn.functional.softmax(-decoded_trains, dim=0)\n",
    "print(p_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([300., 300., 300., 300., 300.,   0.,   0.,   0., 300., 300., 300., 300.,\n",
      "        300., 300.,   0.,   0.,   0., 300., 300.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "lidar = torch.tensor([0, 0, 0, 300, 300, 300, 300, 300, 300])  # Your LIDAR/vision rays data as a PyTorch tensor\n",
    "halfwinsize = 5  # Example window size\n",
    "\n",
    "max_input = 300\n",
    "\n",
    "torch.manual_seed(2)\n",
    "wraparound_data = torch.cat([lidar[-halfwinsize:], lidar, lidar[:halfwinsize]]).float()\n",
    "\n",
    "print(wraparound_data)\n",
    "\n",
    "conv = torch.nn.Conv1d(in_channels=1, out_channels=1, kernel_size=(2*halfwinsize+1), padding='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138.28907775878906\n"
     ]
    }
   ],
   "source": [
    "maximum = (conv.weight.data.clamp(min=0).sum() * max_input+ conv.bias.data).item()\n",
    "minimum = (conv.weight.data.clamp(max=0).sum() * max_input + conv.bias.data).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vec(vec, maximum=None, minimum=None):\n",
    "\n",
    "    if maximum is None or minimum is None:\n",
    "        assert maximum is None and minimum is None\n",
    "        maximum = max(vec)\n",
    "        minimum = min(vec)\n",
    "\n",
    "\n",
    "    max_val = max(abs(maximum), abs(minimum))\n",
    "    maximum = max_val\n",
    "    minimum = -max_val \n",
    "\n",
    "    return [2 * ((x-minimum)/(maximum-minimum)) - 1 for x in vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05548017220892354, -0.5336056710803933, -0.5640488840760428, -0.5812859011533809, -0.32683276079140666, -0.038462985295128815, -0.016573731645048384, 0.31805901652000945, 0.060132418834491386]\n"
     ]
    }
   ],
   "source": [
    "convolved_data = conv(wraparound_data.unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "print(normalize_vec(convolved_data.squeeze().squeeze().detach().numpy(), maximum=maximum, minimum=minimum))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
