{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import snntorch as snn\n",
    "import snntorch.functional as SF\n",
    "import snntorch.spikegen as spikegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 5])\n",
      "torch.Size([2, 8, 5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_spikes = torch.tensor([\n",
    "    [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "])\n",
    "\n",
    "\n",
    "output_spikes_batch = torch.tensor([[\n",
    "    [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    ],\n",
    "    [\n",
    "    [1.0, 1.0, 1.0, 0.0, 1.0],\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    [0.0, 1.0, 0.0, 0.0, 1.0],\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "]])\n",
    "\n",
    "print(output_spikes.shape)\n",
    "print(output_spikes_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_count(spikes):\n",
    "    spike_counts = torch.sum(spikes, dim=1)\n",
    "    action = torch.zeros(spikes.size(0))\n",
    "    max_spike_count = torch.max(spike_counts)\n",
    "    candidates = torch.where(spike_counts == max_spike_count)[0]\n",
    "    if len(candidates) > 1:\n",
    "        action[torch.multinomial(candidates.float(), 1)] = 1\n",
    "    else:\n",
    "        action[candidates] = 1\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_time_to_first_spike(spike_trains):\n",
    "    \n",
    "    decoded_values = torch.full((spike_trains.size(0),), spike_trains.shape[0] + 1)\n",
    "    print(decoded_values)\n",
    "\n",
    "    for i, train in enumerate(spike_trains):\n",
    "\n",
    "        first_spike_time = torch.argmax(train) \n",
    "\n",
    "        if train[first_spike_time] == 1:\n",
    "            decoded_values[i] = first_spike_time.float() + 1\n",
    "\n",
    "    return decoded_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_first_spike(spike_trains):\n",
    "    decoded_vector = [spike_trains.size(0)+1] * spike_trains.size(1)\n",
    "    \n",
    "    for neuron_idx in range(spike_trains.size(1)):\n",
    "        first_spike = (spike_trains[:, neuron_idx] == 1).nonzero(as_tuple=True)[0]\n",
    "        if first_spike.nelement() != 0:\n",
    "            decoded_vector[neuron_idx] = first_spike[0].item() + 1\n",
    "    \n",
    "    return torch.FloatTensor(decoded_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_first_spike_batched(spike_trains):\n",
    "    \"\"\"\n",
    "    Decodes the first spike time from spike trains for batched data using 'time to first spike' method.\n",
    "\n",
    "    Parameters:\n",
    "        spike_trains - The batched spike trains with shape (batch_size, num_steps, num_neurons).\n",
    "\n",
    "    Returns:\n",
    "        decoded_vector - The decoded first spike times with shape (batch_size, num_neurons).\n",
    "    \"\"\"\n",
    "    batch_size = spike_trains.size(0)\n",
    "    num_neurons = spike_trains.size(2)\n",
    "    decoded_vectors = []\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        decoded_vector = [spike_trains.size(1)+1] * num_neurons\n",
    "        \n",
    "        for neuron_idx in range(num_neurons):\n",
    "            first_spike = (spike_trains[batch_idx, :, neuron_idx] == 1).nonzero(as_tuple=True)[0]\n",
    "            if first_spike.nelement() != 0:\n",
    "                decoded_vector[neuron_idx] = first_spike[0].item() + 1\n",
    "        \n",
    "        decoded_vectors.append(decoded_vector)\n",
    "\n",
    "    return torch.FloatTensor(decoded_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3., 1., 9., 5.],\n",
      "        [1., 1., 1., 9., 1.]])\n"
     ]
    }
   ],
   "source": [
    "decoded_trains_batch = decode_first_spike_batched(output_spikes_batch)\n",
    "\n",
    "print(decoded_trains_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Decode the output spikes\n",
    "decoded_trains_batch = decode_count(output_spikes)\n",
    "print(decoded_trains_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoded_trains' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m p_actions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;241m-\u001b[39m\u001b[43mdecoded_trains\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(p_actions)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'decoded_trains' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "p_actions = torch.nn.functional.softmax(-decoded_trains, dim=0)\n",
    "print(p_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([300., 300., 300., 300., 300.,   0.,   0.,   0., 300., 300., 300., 300.,\n",
      "        300., 300.,   0.,   0.,   0., 300., 300.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "lidar = torch.tensor([0, 0, 0, 300, 300, 300, 300, 300, 300])  # Your LIDAR/vision rays data as a PyTorch tensor\n",
    "halfwinsize = 5  # Example window size\n",
    "\n",
    "max_input = 300\n",
    "\n",
    "torch.manual_seed(2)\n",
    "wraparound_data = torch.cat([lidar[-halfwinsize:], lidar, lidar[:halfwinsize]]).float()\n",
    "\n",
    "print(wraparound_data)\n",
    "\n",
    "conv = torch.nn.Conv1d(in_channels=1, out_channels=1, kernel_size=(2*halfwinsize+1), padding='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138.28907775878906\n"
     ]
    }
   ],
   "source": [
    "maximum = (conv.weight.data.clamp(min=0).sum() * max_input+ conv.bias.data).item()\n",
    "minimum = (conv.weight.data.clamp(max=0).sum() * max_input + conv.bias.data).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vec(vec, maximum=None, minimum=None):\n",
    "\n",
    "    if maximum is None or minimum is None:\n",
    "        assert maximum is None and minimum is None\n",
    "        maximum = max(vec)\n",
    "        minimum = min(vec)\n",
    "\n",
    "\n",
    "    max_val = max(abs(maximum), abs(minimum))\n",
    "    maximum = max_val\n",
    "    minimum = -max_val \n",
    "\n",
    "    return [2 * ((x-minimum)/(maximum-minimum)) - 1 for x in vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05548017220892354, -0.5336056710803933, -0.5640488840760428, -0.5812859011533809, -0.32683276079140666, -0.038462985295128815, -0.016573731645048384, 0.31805901652000945, 0.060132418834491386]\n"
     ]
    }
   ],
   "source": [
    "convolved_data = conv(wraparound_data.unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "print(normalize_vec(convolved_data.squeeze().squeeze().detach().numpy(), maximum=maximum, minimum=minimum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to append the contents of a to b\n",
    "def add_episodes(b, a):\n",
    "    for episode in a:\n",
    "        b.append(episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "\n",
    "z = []\n",
    "\n",
    "# Example arrays with varying sizes\n",
    "a1 = np.random.rand(16, 302, 2)\n",
    "a2 = np.random.rand(16, 219, 2)\n",
    "a3 = np.random.rand(16, 301, 2)\n",
    "\n",
    "x1 = [302, 302, 302, 302, 302, 302, 302, 302]\n",
    "x2 = [302, 281, 129, 302, 302, 302, 302, 302]\n",
    "x3 = [302, 302, 302, 302, 302, 302, 302, 301]\n",
    "\n",
    "\n",
    "# Collect data from a1, a2, a3\n",
    "add_episodes(b, a1)\n",
    "add_episodes(b, a2)\n",
    "add_episodes(b, a3)\n",
    "\n",
    "add_episodes(z, x1)\n",
    "add_episodes(z, x2)\n",
    "add_episodes(z, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[302, 302, 302, 302, 302, 302, 302, 302, 302, 281, 129, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 301]\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your observation tensor\n",
    "observation = torch.tensor([300.0000, 450.0000, 0.0000, 4.7124, 0.0000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "threshold = 500  # Define a threshold for rate coding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_spikes(obs, num_steps):\n",
    "    # Normalize observation if needed\n",
    "    normalized_obs = obs / threshold\n",
    "\n",
    "    # Generate spike trains\n",
    "    spike_trains = spikegen.rate(normalized_obs, num_steps=num_steps)\n",
    "\n",
    "    return spike_trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_to_spikes_batched(data, num_steps):\n",
    "    \"\"\"\n",
    "    Encodes analog signals into spike trains using rate encoding.\n",
    "\n",
    "    Parameters:\n",
    "        data - The continuous-valued data to be encoded.\n",
    "        num_steps - The number of time steps for the spike train.\n",
    "\n",
    "    Returns:\n",
    "        spike_train - The encoded spike train.\n",
    "    \"\"\"\n",
    "\n",
    "    # Add a small epsilon to avoid division by zero\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    min = data.min(dim=1, keepdim=True)[0]\n",
    "    max = data.max(dim=1, keepdim=True)[0]\n",
    "\n",
    "    normalized_data = (data - min) / (max - min + epsilon)\n",
    "    normalized_data = torch.clamp(normalized_data, 0, 1)\n",
    "\n",
    "    spike_train = spikegen.rate(normalized_data, num_steps=num_steps)\n",
    "\n",
    "    return spike_train.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mencode_to_spikes_batched\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[8], line 16\u001b[0m, in \u001b[0;36mencode_to_spikes_batched\u001b[1;34m(data, num_steps)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Add a small epsilon to avoid division by zero\u001b[39;00m\n\u001b[0;32m     14\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28mmin\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mmax\u001b[39m \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     19\u001b[0m normalized_data \u001b[38;5;241m=\u001b[39m (data \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mmax\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m \u001b[38;5;241m+\u001b[39m epsilon)\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "print(encode_to_spikes_batched(observation, 50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
