{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import snntorch as snn\n",
    "import snntorch.functional as SF\n",
    "import snntorch.spikegen as spikegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spike_trains(observation, num_steps, threshold, shift):\n",
    "    \"\"\"\n",
    "    Generate spike trains from a single observation using a fixed global threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    - observation: A tensor representing the observation ([observation_dim]).\n",
    "    - num_steps: The number of timesteps for the spike train.\n",
    "    - threshold: A single global threshold value to be used for normalization.\n",
    "    \n",
    "    Returns:\n",
    "    - spike_trains: Tensor of spike trains.\n",
    "    \"\"\"\n",
    "    # Normalize and clip observation\n",
    "    shifted_obs = observation + shift \n",
    "\n",
    "    normalized_obs = shifted_obs / (threshold + 1e-6)  # Avoid division by zero\n",
    "\n",
    "    normalized_obs /= 2\n",
    "\n",
    "    print(\"normalized obs \", normalized_obs)\n",
    "    \n",
    "    normalized_obs = normalized_obs.clamp(0, 1)  # Clip values to be within [0, 1]\n",
    "\n",
    "    \n",
    "    # Generate spike trains\n",
    "    spike_trains = spikegen.rate(normalized_obs, num_steps=num_steps)\n",
    "    \n",
    "    return spike_trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spike_trains_batched(observations, num_steps, threshold, shift):\n",
    "    \"\"\"\n",
    "    Generate spike trains from batched observations using a fixed global threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    - observations: A tensor representing the batched observations ([batch_size, observation_dim]).\n",
    "    - num_steps: The number of timesteps for the spike train.\n",
    "    - threshold: A single global threshold value to be used for normalization.\n",
    "    - shift: A value to shift the observation range to handle negative values.\n",
    "    \n",
    "    Returns:\n",
    "    - spike_trains: Tensor of spike trains with shape (batch_size, num_steps, observation_dim).\n",
    "    \"\"\"\n",
    "    # Normalize and shift observations\n",
    "    normalized_obs = (observations + shift) / (2 * (threshold + 1e-6))  # Avoid division by zero\n",
    "    normalized_obs = normalized_obs.clamp(0, 1)  # Clip values to [0, 1]\n",
    "\n",
    "    # Generate spike trains for each observation in the batch\n",
    "    spike_trains = spikegen.rate(normalized_obs, num_steps=num_steps)\n",
    "    \n",
    "    # Rearrange the output to have shape (batch_size, num_steps, observation_dim)\n",
    "    spike_trains = spike_trains.permute(1, 0, 2)\n",
    "    \n",
    "    return spike_trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spike_counts(spike_trains):\n",
    "    \"\"\"\n",
    "    Get the total number of spikes for each neuron over all timesteps.\n",
    "    \n",
    "    Parameters:\n",
    "    - spike_trains: Tensor of spike trains with shape [num_steps, observation_dim].\n",
    "    \n",
    "    Returns:\n",
    "    - Array of spike counts for each neuron.\n",
    "    \"\"\"\n",
    "    spike_counts = torch.sum(spike_trains, dim=0)\n",
    "    return spike_counts.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spike_counts_batched(spike_trains):\n",
    "    \"\"\"\n",
    "    Get the total number of spikes for each neuron over all timesteps for batched spike trains.\n",
    "    \n",
    "    Parameters:\n",
    "    - spike_trains: Tensor of spike trains with shape [batch_size, num_steps, observation_dim].\n",
    "    \n",
    "    Returns:\n",
    "    - Array of spike counts for each neuron in each observation (shape: [batch_size, observation_dim]).\n",
    "    \"\"\"\n",
    "    # Sum over the time dimension (dim=1) to get spike counts for each neuron in each observation\n",
    "    spike_counts = torch.sum(spike_trains, dim=1)\n",
    "    \n",
    "    return spike_counts.tolist()  # Convert to a list for easier interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_first_spike_batched(spike_trains):\n",
    "    \"\"\"\n",
    "    Decodes the first spike time from spike trains for batched data using 'time to first spike' method.\n",
    "\n",
    "    Parameters:\n",
    "        spike_trains - The batched spike trains with shape (batch_size, num_steps, num_neurons).\n",
    "\n",
    "    Returns:\n",
    "        decoded_vector - The decoded first spike times with shape (batch_size, num_neurons).\n",
    "    \"\"\"\n",
    "    batch_size = spike_trains.size(0)\n",
    "    num_neurons = spike_trains.size(2)\n",
    "    decoded_vectors = []\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        decoded_vector = [spike_trains.size(1)+1] * num_neurons\n",
    "        \n",
    "        for neuron_idx in range(num_neurons):\n",
    "            first_spike = (spike_trains[batch_idx, :, neuron_idx] == 1).nonzero(as_tuple=True)[0]\n",
    "            if first_spike.nelement() != 0:\n",
    "                decoded_vector[neuron_idx] = first_spike[0].item() + 1\n",
    "        \n",
    "        decoded_vectors.append(decoded_vector)\n",
    "\n",
    "    return torch.FloatTensor(decoded_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_first_spike(spike_trains):\n",
    "    \"\"\"\n",
    "    Decodes the first spike time from spike trains using the 'time to first spike' method for non-batched data.\n",
    "\n",
    "    Parameters:\n",
    "        spike_trains - The spike trains with shape (num_steps, num_neurons).\n",
    "\n",
    "    Returns:\n",
    "        decoded_vector - The decoded first spike times with shape (num_neurons,).\n",
    "    \"\"\"\n",
    "    num_steps = spike_trains.size(0)\n",
    "    num_neurons = spike_trains.size(1)\n",
    "    \n",
    "    # Initialize decoded vector with default values greater than the maximum possible spike time\n",
    "    decoded_vector = [num_steps + 1] * num_neurons\n",
    "\n",
    "    # Iterate over each neuron to find the first spike time\n",
    "    for neuron_idx in range(num_neurons):\n",
    "        first_spike = (spike_trains[:, neuron_idx] == 1).nonzero(as_tuple=True)[0]\n",
    "        if first_spike.nelement() != 0:\n",
    "            decoded_vector[neuron_idx] = first_spike[0].item() + 1  # +1 to convert 0-based index to 1-based time step\n",
    "\n",
    "    return torch.FloatTensor(decoded_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_count(spikes):\n",
    "    spike_counts = torch.sum(spikes, dim=1)\n",
    "    action = torch.zeros(spikes.size(0))\n",
    "    max_spike_count = torch.max(spike_counts)\n",
    "    candidates = torch.where(spike_counts == max_spike_count)[0]\n",
    "    if len(candidates) > 1:\n",
    "        action[torch.multinomial(candidates.float(), 1)] = 1\n",
    "    else:\n",
    "        action[candidates] = 1\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "normalized obs  tensor([0.9000, 0.6667, 0.7000, 0.0000, 0.6592, 0.0500, 0.9000, 0.6500])\n",
      "shape of spike trains tensor([[1., 0., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 0., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [0., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 0., 0., 0., 1., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [0., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 1., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 0., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 0., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 0., 0., 1., 0., 1., 1.],\n",
      "        [0., 1., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 0., 0., 0., 1., 0., 1., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 0., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 1., 1., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 0., 0., 0., 1., 1.],\n",
      "        [0., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0.],\n",
      "        [1., 1., 0., 0., 1., 0., 1., 1.]])\n",
      "First spike times: tensor([  1.,   3.,   2., 101.,   2.,   2.,   1.,   1.])\n",
      "Spike counts: [91.0, 70.0, 71.0, 0.0, 62.0, 4.0, 92.0, 69.0]\n"
     ]
    }
   ],
   "source": [
    "# non-batch version\n",
    "observation = torch.tensor([1.2, 0.5, 2.0, -5, 1.0, -4.5, 0.8, 0.3])  # Example observation\n",
    "threshold = torch.tensor([1.5, 1.5, 5, 5, 3.14, 5, 1, 1])\n",
    "shift = torch.tensor([1.5, 1.5, 5, 5, 3.14, 5, 1, 1])\n",
    "print(observation.shape)\n",
    "spike_trains = generate_spike_trains(observation, num_steps=100, threshold=threshold, shift=shift)\n",
    "\n",
    "print(\"shape of spike trains\",spike_trains)  # [num_steps, observation_dim]\n",
    "# Get the first spike times as an array\n",
    "first_spike_times = decode_first_spike(spike_trains)\n",
    "print(\"First spike times:\", first_spike_times)\n",
    "\n",
    "# Get the spike counts as an array\n",
    "spike_counts = get_spike_counts(spike_trains)\n",
    "print(\"Spike counts:\", spike_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "torch.Size([4, 100, 8])\n",
      "First spike times: tensor([[  1.,   1., 101.,   2.,   1.,  40.,   1.,   2.],\n",
      "        [  2.,   2.,   1.,   1.,   2.,   1.,   5.,   5.],\n",
      "        [  1.,   1.,   2.,   1.,   3.,   1.,   1.,   1.],\n",
      "        [  1.,   2.,   4.,   1.,   3.,   1.,   1.,   1.]])\n",
      "Spike counts: tensor([[100.,  33.,   0.,  52.,  67.,   5.,  91.,  68.],\n",
      "        [ 54.,  65.,  31.,  71.,  60.,  23.,  12.,  39.],\n",
      "        [  6.,  38.,  45.,  46.,  36.,  55.,  65.,  51.],\n",
      "        [ 68.,  62.,  47.,  48.,  54.,  48.,  50.,  56.]])\n"
     ]
    }
   ],
   "source": [
    "# batch version\n",
    "observation = torch.tensor([[1.5, -0.5, -5.0, -0.0, 1.0, -4.5, 0.8, 0.3],\n",
    "                             [0.2, 0.5, -2.0, 1.0, 0.5, -1.5, -0.8, -0.3],\n",
    "                             [-1.2, -0.5, -0.2, -0.3, -1.0, 0.4, 0.2, 0.1],\n",
    "                             [0.5, 0.5, 0.2, 0.3, 0.1, 0.0, -0.2, 0.3]])\n",
    "\n",
    "threshold = torch.tensor([1.5, 1.5, 5, 5, 3.14, 5, 1, 1])\n",
    "shift = torch.tensor([1.5, 1.5, 5, 5, 3.14, 5, 1, 1])\n",
    "print(observation.shape)\n",
    "spike_trains = generate_spike_trains_batched(observation, num_steps=100, threshold=threshold, shift=shift)\n",
    "\n",
    "print(spike_trains.shape)  # [num_steps, observation_dim]\n",
    "# Get the first spike times as an array\n",
    "first_spike_times = decode_first_spike_batched(spike_trains)\n",
    "print(\"First spike times:\", first_spike_times)\n",
    "\n",
    "# Get the spike counts as an array\n",
    "spike_counts = get_spike_counts_batched(spike_trains)\n",
    "\n",
    "spike_counts = torch.tensor(spike_counts)\n",
    "print(\"Spike counts:\", spike_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
