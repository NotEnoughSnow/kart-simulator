{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import spikegen\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from torch.distributions import MultivariateNormal\n",
    "import snntorch.functional as SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps_per_batch = 4800  # Number of timesteps to run per batch\n",
    "max_timesteps_per_episode = 1600  # Max number of timesteps per episode\n",
    "n_updates_per_iteration = 5  # Number of times to update actor/critic per iteration\n",
    "lr = 0.005  # Learning rate of actor optimizer\n",
    "gamma = 0.95  # Discount factor to be applied when calculating Rewards-To-Go\n",
    "clip = 0.2  # Recommended 0.2, helps define the threshold to clip the ratio during SGA\n",
    "\n",
    "# Miscellaneous parameters\n",
    "render = True  # If we should render during rollout\n",
    "render_every_i = 10  # Only render every n iterations\n",
    "save_freq = 10  # How often we save in number of iterations\n",
    "seed = None  # Sets the seed of our program, used for reproducibility of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNN def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 300  # number of hidden neurons\n",
    "\n",
    "\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_steps):\n",
    "        super(SNN, self).__init__()\n",
    "\n",
    "        self.num_steps = num_steps\n",
    "        beta1 = 0.9\n",
    "        beta2 = torch.rand((output_size), dtype = torch.float) # independent decay rate for each leaky neuron in layer 2: [0, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.lif1 = snn.Leaky(beta=beta1)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.lif2 = snn.Leaky(beta=beta2, learn_beta=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        spk2_rec = [] # record output spikes\n",
    "        mem2_rec = [] # record output hidden states\n",
    "\n",
    "        for step in range(self.num_steps):\n",
    "            cur1 = self.fc1(x[:, step, :])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "\n",
    "            spk2_rec.append(spk2) # record spikes\n",
    "            mem2_rec.append(mem2) # record membrane\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=1), torch.stack(mem2_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 64\n",
    "\n",
    "class SNN_2(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_steps):\n",
    "        super(SNN_2, self).__init__()\n",
    "        self.num_steps = num_steps\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.lif1 = snn.Leaky(beta=0.9)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.lif2 = snn.Leaky(beta=0.9)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.lif3 = snn.Leaky(beta=0.9, learn_beta=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize the membrane potentials\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk3_rec = []\n",
    "\n",
    "        for step in range(self.num_steps):\n",
    "            cur1 = self.fc1(x[:,step,:])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            cur3 = self.fc3(spk2)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "\n",
    "            spk3_rec.append(spk3)\n",
    "\n",
    "        return torch.stack(spk3_rec, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_time_to_first_spike(spike_trains):\n",
    "    decoded_vector = [spike_trains.size(0)+1] * spike_trains.size(1)\n",
    "    \n",
    "    for neuron_idx in range(spike_trains.size(1)):\n",
    "        first_spike = (spike_trains[:, neuron_idx] == 1).nonzero(as_tuple=True)[0]\n",
    "        if first_spike.nelement() != 0:\n",
    "            decoded_vector[neuron_idx] = first_spike[0].item() + 1\n",
    "    \n",
    "    return torch.FloatTensor(decoded_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_from_spikes_count(spikes):\n",
    "    spike_counts = torch.sum(spikes, dim=1)\n",
    "    action = torch.zeros(spikes.size(0))\n",
    "    max_spike_count = torch.max(spike_counts)\n",
    "    candidates = torch.where(spike_counts == max_spike_count)[0]\n",
    "    if len(candidates) > 1:\n",
    "        action[torch.multinomial(candidates.float(), 1)] = 1\n",
    "    else:\n",
    "        action[candidates] = 1\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_to_spikes(data, num_steps):\n",
    "    \"\"\"\n",
    "    Encodes analog signals into spike trains using rate encoding.\n",
    "\n",
    "    Parameters:\n",
    "        data - The continuous-valued data to be encoded.\n",
    "        num_steps - The number of time steps for the spike train.\n",
    "\n",
    "    Returns:\n",
    "        spike_train - The encoded spike train.\n",
    "    \"\"\"\n",
    "\n",
    "    # Add a small epsilon to avoid division by zero\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    # Normalize the data to be between 0 and 1\n",
    "    normalized_data = (data - data.min()) / (data.max() - data.min() + epsilon)\n",
    "\n",
    "    # Convert normalized data to spike trains\n",
    "    # TODO rate vs latency vs delta\n",
    "    spike_train = spikegen.rate(normalized_data, num_steps=num_steps)\n",
    "\n",
    "    return spike_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rtgs(batch_rews):\n",
    "    \"\"\"\n",
    "        Compute the Reward-To-Go of each timestep in a batch given the rewards.\n",
    "\n",
    "        Parameters:\n",
    "            batch_rews - the rewards in a batch, Shape: (number of episodes, number of timesteps per episode)\n",
    "\n",
    "        Return:\n",
    "            batch_rtgs - the rewards to go, Shape: (number of timesteps in batch)\n",
    "    \"\"\"\n",
    "    # The rewards-to-go (rtg) per episode per batch to return.\n",
    "    # The shape will be (num timesteps per episode)\n",
    "    batch_rtgs = []\n",
    "\n",
    "    # Iterate through each episode\n",
    "    for ep_rews in reversed(batch_rews):\n",
    "\n",
    "        discounted_reward = 0  # The discounted reward so far\n",
    "\n",
    "        # Iterate through all rewards in the episode. We go backwards for smoother calculation of each\n",
    "        # discounted return (think about why it would be harder starting from the beginning)\n",
    "        for rew in reversed(ep_rews):\n",
    "            discounted_reward = rew + discounted_reward * gamma\n",
    "            batch_rtgs.insert(0, discounted_reward)\n",
    "\n",
    "    # Convert the rewards-to-go into a tensor\n",
    "    batch_rtgs = torch.tensor(batch_rtgs, dtype=torch.float)\n",
    "\n",
    "    return batch_rtgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dim = 5\n",
    "act_dim = 5\n",
    "\n",
    "# Define the number of time steps for the simulation\n",
    "num_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\n",
    "    \"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Initialize actor and critic networks\n",
    "actor = SNN(obs_dim, act_dim, num_steps).to(device)  # ALG STEP 1\n",
    "critic = SNN(obs_dim, 1, num_steps).to(device)\n",
    "\n",
    "# Initialize optimizers for actor and critic\n",
    "actor_optim = torch.optim.Adam(actor.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "critic_optim = torch.optim.Adam(critic.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "\n",
    "cov_var = torch.full(size=(act_dim,), fill_value=0.5)\n",
    "cov_mat = torch.diag(cov_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### observation needs to be spike trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first observation, from reset\n",
    "obs = torch.tensor([300.0000, 450.0000,   0.0000,   4.7124,   0.0000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 5])\n"
     ]
    }
   ],
   "source": [
    "# TODO observations -> spike trains\n",
    "obs_spike_trains = encode_to_spikes(obs ,num_steps=num_steps)\n",
    "\n",
    "reshaped = torch.reshape(obs_spike_trains, [1, 50, 5])\n",
    "print(reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from get_action() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 5])\n"
     ]
    }
   ],
   "source": [
    "# TODO spike trains -> mean action\n",
    "mean_spike_trains = actor(reshaped)\n",
    "\n",
    "mean_spike_trains = mean_spike_trains[0].detach()\n",
    "\n",
    "print(mean_spike_trains.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([51., 51., 51., 51., 51.])\n"
     ]
    }
   ],
   "source": [
    "# TODO decode with \n",
    "\n",
    "mean = decode_time_to_first_spike(np.reshape(mean_spike_trains, [50,5]))\n",
    "\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([51., 51., 51., 51., 51.])\n",
      "[50.26872  51.12235  49.84141  50.737286 50.650578]\n",
      "tensor(-4.9450)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a distribution with the mean action and std from the covariance matrix above.\n",
    "# For more information on how this distribution works, check out Andrew Ng's lecture on it:\n",
    "# https://www.youtube.com/watch?v=JjB58InuTqM\n",
    "dist = MultivariateNormal(mean, cov_mat)\n",
    "\n",
    "# Sample an action from the distribution\n",
    "action = dist.sample()\n",
    "\n",
    "# Calculate the log probability for that action\n",
    "log_prob = dist.log_prob(action)\n",
    "\n",
    "print(mean.detach())\n",
    "print(action.detach().numpy())\n",
    "print(log_prob.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rollout\n",
    "\n",
    "# batch obs\n",
    "batch_obs = torch.tensor([[300.0000, 450.0000,   0.0000,   4.7124,   0.0000],\n",
    "        [300.0667, 450.0000,   3.9801,   4.7124,   0.0000],\n",
    "        [300.1997, 450.0000,   7.9404,   4.7124,   0.0000],\n",
    "        [300.0000, 450.0000,   0.0000,   4.7124,   0.0000],\n",
    "        [300.0667, 450.0000,   3.9801,   4.7124,   0.0000],\n",
    "        [300.1997, 450.0000,   7.9404,   4.7124,   0.0000]])\n",
    "\n",
    "# batch actions\n",
    "batch_acts =  torch.tensor([[13.1795, 10.1534, 10.7613,  9.3591, -7.8791],\n",
    "        [13.7555,  9.6675, 10.0287,  9.6279, -6.4844],\n",
    "        [13.1954, 10.4574,  9.9011,  9.5315, -7.1549],\n",
    "        [13.4455,  9.4522,  9.5629, 10.1283, -6.6890],\n",
    "        [14.7801,  8.4991,  8.6375,  9.9466, -6.9821],\n",
    "        [13.8373, 10.2118, 10.8795,  8.7003, -6.5202]])\n",
    "\n",
    "# batch log prob\n",
    "batch_log_probs = torch.tensor([-5.0741, -3.2771, -3.4157, -4.1163, -8.0700, -4.7627])\n",
    "\n",
    "# batch rewards\n",
    "batch_rtgs = torch.tensor([-3.1173, -2.1154, -1.0746, -3.1173, -2.1154, -1.0746])\n",
    "\n",
    "# batch lengths\n",
    "batch_lens = [3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO batch_obs to spike trains batch obs\n",
    "\n",
    "batch_obs_spike_trains = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spike trains actions / preductions -> actions / predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(batch_obs, batch_acts):\n",
    "    \"\"\"\n",
    "        Estimate the values of each observation, and the log probs of\n",
    "        each action in the most recent batch with the most recent\n",
    "        iteration of the actor network. Should be called from learn.\n",
    "\n",
    "        Parameters:\n",
    "            batch_obs - the observations from the most recently collected batch as a tensor.\n",
    "                        Shape: (number of timesteps in batch, dimension of observation)\n",
    "            batch_acts - the actions from the most recently collected batch as a tensor.\n",
    "                        Shape: (number of timesteps in batch, dimension of action)\n",
    "\n",
    "        Return:\n",
    "            V - the predicted values of batch_obs\n",
    "            log_probs - the log probabilities of the actions taken in batch_acts given batch_obs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query critic network for a value V for each batch_obs. Shape of V should be same as batch_rtgs\n",
    "    V = critic(batch_obs_spike_trains).squeeze()\n",
    "\n",
    "    # Calculate the log probabilities of batch actions using most recent actor network.\n",
    "    # This segment of code is similar to that in get_action()\n",
    "    mean = actor(batch_obs)\n",
    "    dist = MultivariateNormal(mean, cov_mat)\n",
    "    log_probs = dist.log_prob(batch_acts)\n",
    "\n",
    "    # Return the value vector V of each observation in the batch\n",
    "    # and log probabilities log_probs of each action in the batch\n",
    "    return V, log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate advantage at k-th iteration\n",
    "V, _ = evaluate(batch_obs, batch_acts)\n",
    "A_k = batch_rtgs - V.detach()\n",
    "\n",
    "print(V)\n",
    "print(A_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the advantage\n",
    "A_k = (A_k - A_k.mean()) / (A_k.std() + 1e-10)\n",
    "\n",
    "print(A_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate V_phi and pi_theta(a_t | s_t)\n",
    "V, curr_log_probs = evaluate(batch_obs, batch_acts)\n",
    "\n",
    "# Calculate the ratio pi_theta(a_t | s_t) / pi_theta_k(a_t | s_t)\n",
    "# NOTE: we just subtract the logs, which is the same as\n",
    "# dividing the values and then canceling the log with e^log.\n",
    "# For why we use log probabilities instead of actual probabilities,\n",
    "# here's a great explanation:\n",
    "# https://cs.stackexchange.com/questions/70518/why-do-we-use-the-log-in-gradient-based-reinforcement-algorithms\n",
    "# TL;DR makes gradient ascent easier behind the scenes.\n",
    "ratios = torch.exp(curr_log_probs - batch_log_probs)\n",
    "\n",
    "print(V)\n",
    "print(curr_log_probs)\n",
    "print(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate surrogate losses.\n",
    "surr1 = ratios * A_k\n",
    "surr2 = torch.clamp(ratios, 1 - clip, 1 + clip) * A_k\n",
    "\n",
    "print(surr1)\n",
    "print(surr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate actor and critic losses.\n",
    "# NOTE: we take the negative min of the surrogate losses because we're trying to maximize\n",
    "# the performance function, but Adam minimizes the loss. So minimizing the negative\n",
    "# performance function maximizes it.\n",
    "actor_loss = (-torch.min(surr1, surr2)).mean()\n",
    "critic_loss = nn.MSELoss()(V, batch_rtgs)\n",
    "\n",
    "print(actor_loss)\n",
    "print(critic_loss)\n",
    "\n",
    "# Calculate gradients and perform backward propagation for actor network\n",
    "actor_optim.zero_grad()\n",
    "actor_loss.backward(retain_graph=True)\n",
    "actor_optim.step()\n",
    "\n",
    "# Calculate gradients and perform backward propagation for critic network\n",
    "critic_optim.zero_grad()\n",
    "critic_loss.backward()\n",
    "critic_optim.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
